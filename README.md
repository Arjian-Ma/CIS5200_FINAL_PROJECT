# ESE5380 Final Project - Directory Structure

## Overview
This project implements a comprehensive machine learning pipeline for analyzing League of Legends match data using various models (RNN, LSTM, Transformer, Diffusion) and traditional ML approaches.

## Directory Structure

```
ESE5380_FINAL/
â”œâ”€â”€ ğŸ“ configs/                    # Configuration files
â”œâ”€â”€ ğŸ“ data/                      # Data storage (organized by processing stage)
â”‚   â”œâ”€â”€ ğŸ“ raw/                   # Original/raw data files
â”‚   â”œâ”€â”€ ğŸ“ processed/             # Cleaned and feature-engineered data
â”‚   â””â”€â”€ ğŸ“ splits/                # Train/validation/test data splits
â”œâ”€â”€ ğŸ“ models/                    # Saved model files and checkpoints
â”‚   â”œâ”€â”€ ğŸ“ rnn/                   # RNN model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ lstm/                  # LSTM model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ transformer/           # Transformer model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ diffusion/             # Diffusion model checkpoints
â”‚   â””â”€â”€ ğŸ“ baselines/             # Traditional ML models (RF, XGBoost)
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks for analysis
â”œâ”€â”€ ğŸ“ results/                   # Model outputs and visualizations
â”‚   â”œâ”€â”€ ğŸ“ logs/                  # Training logs
â”‚   â”œâ”€â”€ ğŸ“ checkpoints/           # Model checkpoints
â”‚   â””â”€â”€ ğŸ“ predictions/           # Model predictions
â”œâ”€â”€ ğŸ“ scripts/                   # Training and utility scripts
â”œâ”€â”€ ğŸ“ src/                       # Source code (Python modules)
â”‚   â”œâ”€â”€ ğŸ“ data/                  # Data processing modules
â”‚   â”œâ”€â”€ ğŸ“ models/                # Model definitions
â”‚   â”œâ”€â”€ ğŸ“ training/              # Training utilities
â”‚   â””â”€â”€ ğŸ“ evaluation/            # Evaluation metrics
â”œâ”€â”€ ğŸ“ timeline_data/             # Raw timeline JSON files (temporary)
â”œâ”€â”€ ğŸ“„ README.md                  # Project documentation
â””â”€â”€ ğŸ“„ PARSER_README.md           # Riot API parser documentation
```

## Detailed Directory Descriptions

### ğŸ“ `configs/`
**Purpose**: Configuration files for different components
- **`data_config.yaml`**: Data processing parameters (splits, features, etc.)
- **`model_config.yaml`**: Model hyperparameters and architecture settings
- **`training_config.yaml`**: Training parameters (batch size, learning rate, etc.)

### ğŸ“ `data/`
**Purpose**: Organized data storage following ML best practices

#### ğŸ“ `data/raw/`
**Purpose**: Original, unprocessed data files
- **`xy_rows.csv`**: Raw match data with 10 rows per timestamp (1 per player)
- **`opgg_leaderboard.csv`**: Player leaderboard data for API scraping
- **`timeline_data/`**: Raw timeline JSON files from Riot API (should be moved here)

#### ğŸ“ `data/processed/`
**Purpose**: Cleaned and feature-engineered data
- **`featured_data.csv`**: Aggregated team-level features (548 rows)
- **`featured_data_with_scores.csv`**: Data with composite player scores (548 rows)

#### ğŸ“ `data/splits/`
**Purpose**: Train/validation/test data splits
- **`train.csv`**: Training data (70% of matches)
- **`val.csv`**: Validation data (15% of matches)
- **`test.csv`**: Test data (15% of matches)

### ğŸ“ `models/`
**Purpose**: Saved model files and checkpoints
- **`rnn/`**: RNN model weights and checkpoints
- **`lstm/`**: LSTM model weights and checkpoints
- **`transformer/`**: Transformer model weights and checkpoints
- **`diffusion/`**: Diffusion model weights and checkpoints
- **`baselines/`**: Traditional ML models (Random Forest, XGBoost, etc.)

### ğŸ“ `results/`
**Purpose**: Model outputs, visualizations, and analysis results
- **`logs/`**: Training logs and metrics
- **`checkpoints/`**: Model checkpoints during training
- **`predictions/`**: Model predictions on test data
- **`*.png`**: Visualization plots (feature importance, results, etc.)

### ğŸ“ `src/`
**Purpose**: Source code organized by functionality

#### ğŸ“ `src/data/`
**Purpose**: Data processing and feature engineering modules
- **`riot_parser.py`**: Riot API parser for collecting match timeline data
- **`build_xy_dataframe.py`**: Converts timeline JSONs to structured DataFrame
- **`data_featuring.py`**: Feature engineering (team aggregation, differences)
- **`data_featuring_score.py`**: Player scoring system (offensive, defensive, etc.)
- **`ID.py`**: Player ID management utilities
- **`RiotData.py`**: Riot API data structures

#### ğŸ“ `src/models/`
**Purpose**: Model definitions and implementations
- **`RNN.py`**: RNN model implementation
- **`random_forest.py`**: Random Forest baseline model
- **`gradient_tree_boost.py`**: Gradient Boosting model
- **`regression.py`**: Linear regression baseline

#### ğŸ“ `src/training/`
**Purpose**: Training utilities and trainers
- **`trainer.py`**: Generic training framework
- **`utils.py`**: Training utilities and helpers

#### ğŸ“ `src/evaluation/`
**Purpose**: Evaluation metrics and analysis
- **`metrics.py`**: Model evaluation metrics

### ğŸ“ `scripts/`
**Purpose**: Training and utility scripts
- **`train_lstm.py`**: LSTM training script
- **`train_transformer.py`**: Transformer training script
- **`train_diffusion.py`**: Diffusion model training script

### ğŸ“ `notebooks/`
**Purpose**: Jupyter notebooks for analysis and exploration
- **`data_exploration.ipynb`**: Data exploration and visualization

### ğŸ“ `timeline_data/` (Temporary)
**Purpose**: Currently contains raw timeline JSON files
- **Note**: This should be moved to `data/raw/timeline_data/` for proper organization
- **Contains**: 60+ timeline JSON files from Riot API

## Data Flow

```
Raw Data â†’ Feature Engineering â†’ Model Training â†’ Evaluation
    â†“              â†“                    â†“            â†“
timeline_data/ â†’ data/processed/ â†’ models/ â†’ results/
```

## Key Features

### ğŸ¯ **Data Leakage Prevention**
- Removed deterministic features that directly compute targets
- Proper temporal splits to prevent future information leakage

### ğŸ”„ **Modular Architecture**
- Clean separation between data processing, modeling, and evaluation
- Reusable components for different model types

### ğŸ“Š **Multi-Model Support**
- Sequential models: RNN, LSTM, Transformer, Diffusion
- Traditional ML: Random Forest, XGBoost, Linear Regression
- Proper PyTorch DataLoader implementation

### ğŸ—ï¸ **ML Best Practices**
- Proper train/val/test splits by match (not by row)
- Configuration-driven approach
- Comprehensive logging and checkpointing
- Feature engineering pipeline

## Usage

1. **Data Collection**: Run `src/data/riot_parser.py` to collect timeline data
2. **Feature Engineering**: Run `src/data/data_featuring.py` and `src/data/data_featuring_score.py`
3. **Model Training**: Use scripts in `scripts/` directory
4. **Evaluation**: Check results in `results/` directory

## Notes

- The `timeline_data/` directory should be moved to `data/raw/timeline_data/` for proper organization
- All data processing scripts have been updated to use the new directory structure
- Configuration files provide easy parameter management
- The project follows ML engineering best practices with proper separation of concerns
